{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import argparse\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "try:\n",
    "    import keras.backend.tensorflow_backend as KTF\n",
    "except ImportError as e:\n",
    "    KTF = None\n",
    "    TENSORFLOW_IMPORT_ERROR = e\n",
    "\n",
    "from rnd_libs.lib.keras.train import TheanoTrainer\n",
    "from rnd_libs.lib.keras.test import TheanoTester\n",
    "from rnd_libs.lib.keras.train_captions import TheanoTrainerCaptions\n",
    "from rnd_libs.lib.keras.test_captions import TheanoTesterCaptions\n",
    "from rnd_libs.lib.keras.lmdb_parser import LMDBParser\n",
    "from rnd_libs.lib.keras.test import f as preds_Aggr\n",
    "trainer_dict = {'concepts': TheanoTrainer, 'captions': TheanoTrainerCaptions}\n",
    "tester_dict = {'concepts': TheanoTester, 'captions': TheanoTesterCaptions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_bn:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_nonlin:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_1:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_bn_1:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_nonlin_1:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added padding_conv2:ZeroPadding2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_2:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_bn_2:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_nonlin_2:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added pool:MaxPooling2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_3:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_bn_3:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_nonlin_3:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_4:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_bn_4:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added conv_nonlin_4:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added pool_1:MaxPooling2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-A mixed\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-A mixed_1\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-A mixed_2\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-B mixed_3\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-C mixed_4\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m31s][INFO] Added Inception-C mixed_5\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added Inception-C mixed_6\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added Inception-C mixed_7\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added Inception-D mixed_8\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added Inception-E mixed_9\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added Inception-E mixed_10\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Added pool3:AveragePooling\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] {'W_constraint': None, 'b_constraint': None, 'name': 'Convolution2D', 'custom_name': 'softmax', 'subsample': (1, 1), 'activation': 'linear', 'trainable': True, 'dim_ordering': 'th', 'nb_col': 1, 'cache_enabled': True, 'init': 'glorot_uniform', 'nb_filter': 7735, 'b_regularizer': None, 'W_regularizer': None, 'nb_row': 1, 'activity_regularizer': None, 'border_mode': 'valid'}\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] Weights Initalized from /nas2/deliverables/v16/model-full-conv.hdf5\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h25m32s][INFO] inception_v3_fc Model defined from /nas2/praveen/home/rnd-libs/rnd_libs/models/keras/inception_v3_fc.yaml\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:788: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:788: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:788: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:793: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='average_exc_pad')\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:793: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='average_exc_pad')\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/keras/backend/theano_backend.py:793: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='average_exc_pad')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08 Feb 2017 18h26m10s][INFO] inception_v3_fc Model compiled\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tester = tester_dict['concepts']('./configs/visualize_models.yaml', 0, True)\n",
    "tester.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_bn:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_nonlin:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_1:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_bn_1:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_nonlin_1:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added padding_conv2:ZeroPadding2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_2:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_bn_2:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_nonlin_2:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added pool:MaxPooling2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_3:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_bn_3:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_nonlin_3:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_4:Convolution2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_bn_4:BatchNormalization\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added conv_nonlin_4:Activation\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added pool_1:MaxPooling2D\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-A mixed\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-A mixed_1\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-A mixed_2\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-B mixed_3\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-C mixed_4\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-C mixed_5\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-C mixed_6\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-C mixed_7\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m13s][INFO] Added Inception-D mixed_8\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Added Inception-E mixed_9\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Added Inception-E mixed_10\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Added pool3:AveragePooling\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Added flatten:Flatten\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Added softmax:Dense\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] {'W_constraint': None, 'b_constraint': None, 'name': 'Dense', 'custom_name': 'softmax', 'activity_regularizer': None, 'trainable': True, 'cache_enabled': True, 'init': 'glorot_uniform', 'activation': 'linear', 'input_dim': None, 'b_regularizer': None, 'W_regularizer': None, 'output_dim': 7735}\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] Weights Initalized from /nas2/deliverables/v16/model.hdf5\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m14s][INFO] inception_v3 Model defined from /nas2/praveen/home/rnd-libs/rnd_libs/models/keras/inception_v3.yaml\u001b[0m\n",
      "\u001b[32m[08 Feb 2017 18h26m47s][INFO] inception_v3 Model compiled\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#tester_orig = tester_dict['concepts']('./configs/visualize_orig_model.yaml', 0, True)\n",
    "#tester_orig.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08 Feb 2017 18h26m47s][INFO] Removing getty scrapped images from validation data\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10406"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get validation images for visualization. gnd variable contains ground truth.\n",
    "# def contains(string,substring):\n",
    "#     if substring not in string:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "image_filenames,gnd,indexes=tester.get_images_frVisualization()\n",
    "#filter=[contains(img,'getty-concept-sourcing') for img in image_filenames]\n",
    "# ind=np.where(np.array(filter)==True)[0]\n",
    "# image_filenames=np.array(image_filenames)[ind]\n",
    "# gnd=np.array(gnd)[ind]\n",
    "len(image_filenames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08 Feb 2017 18h26m52s][INFO] Fetching 1 images took 0.0446 secs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7735)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick test of model.\n",
    "import numpy as np\n",
    "size=299\n",
    "tester.im_h=size\n",
    "tester.im_w=size\n",
    "tester.resize_test=True\n",
    "\n",
    "pix,basenames=tester.fetch_images([image_filenames[10095]])\n",
    "(predictions, features) = tester.inference(pix)\n",
    "predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filter visualizations.\n",
    "\n",
    "# %matplotlib inline\n",
    "# import pylab as pl\n",
    "# import matplotlib.cm as cm\n",
    "# print predictions.shape\n",
    "# filterno=1535\n",
    "# pl.imshow(predictions[0,filterno,:,:])\n",
    "\n",
    "# print predictions[0,filterno,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10406"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gnd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.eyeem.com/thumb/w/420/de030f07eb80f75c07f730ad68f663eac1c78dcc-1431157977\n"
     ]
    }
   ],
   "source": [
    "#connect to sql and do sample check of connection by quering two images.\n",
    "import sqlalchemy\n",
    "\n",
    "engine     = sqlalchemy.create_engine('mysql+pymysql://ro:rj5XYM4V9QKwy5XScdG@mysql.ro.eyeem.com')\n",
    "connection = engine.connect()\n",
    "\n",
    "IDs = [64896557]\n",
    "\n",
    "query = \"SELECT id, filename, width, height FROM eyeem.eyeem_photo WHERE id IN (%s)\" % str(IDs).strip(\"[]\")\n",
    "\n",
    "query_results = connection.execute(query)\n",
    "\n",
    "IDs, filenames, widths, heights = zip(*query_results)\n",
    "print 'http://cdn.eyeem.com/thumb/w/420/'+filenames[0]\n",
    "#IDs_filenames[str(IDs[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1467]),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query all 20K images in validation data\n",
    "#to get the actual keys in the server.\n",
    "import os \n",
    "IDs=[]\n",
    "for i in image_filenames:\n",
    "    IDs.append(os.path.splitext(os.path.basename(i))[0])\n",
    "query = \"SELECT id, filename, width, height FROM eyeem.eyeem_photo WHERE id IN (%s)\" % str(IDs).strip(\"[]\")\n",
    "query_results = connection.execute(query)\n",
    "#query_results = connection.execute(query)\n",
    "IDs_existing, filenames, widths, heights = zip(*query_results)\n",
    "ID_=[]\n",
    "for i in IDs_existing:\n",
    "    ID_.append(str(i))\n",
    "IDs_existing=ID_\n",
    "\n",
    "IDs_filenames=dict(zip(IDs_existing,filenames))\n",
    "#IDs_filenames\n",
    "#import numpy as np\n",
    "np.where(np.array(IDs_existing)=='42050402')\n",
    "#IDs_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select random nundom images for visualization.\n",
    "\n",
    "import numpy as np\n",
    "from numpy import int64\n",
    "num_imgs_FrVisualization=500\n",
    "\n",
    "\n",
    "\n",
    "slicing=np.random.permutation(range(len(IDs_existing)))[0:num_imgs_FrVisualization]\n",
    "slicing=[1467]\n",
    "ind_imgs=np.array(IDs_existing)[slicing]\n",
    "IDs=[]\n",
    "subset_filenames=[]\n",
    "#subset_filenames_servers=[]\n",
    "for i in range(len(image_filenames)):\n",
    "    base=os.path.splitext(os.path.basename(image_filenames[i]))[0]\n",
    "    \n",
    "    if base in ind_imgs:\n",
    "        #print image_filenames[i]\n",
    "        subset_filenames.append(image_filenames[i])\n",
    "        #IDs.append(base)\n",
    "        IDs.append(base)\n",
    "# for ID in IDs:\n",
    "#     print IDs_filenames[ID]\n",
    "#IDs \n",
    "#IDs_filenames[161332810]\n",
    "#IDs_filenames[83278966]\n",
    "#subset_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42050402</td>\n",
       "      <td><img src=http://cdn.eyeem.com/thumb/w/200/ceb704440991517303f0ae74a4b58e7bfb383043-1406043086></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML,Image\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "df = pd.DataFrame(list(IDs), columns=['IDs'])\n",
    "df['images'] = df['IDs'].apply(lambda x:\"<img src=http://cdn.eyeem.com/thumb/w/200/{0}>\".format(IDs_filenames[x]))\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resize\n",
      "\u001b[32m[09 Feb 2017 14h30m23s][INFO] Fetching 1 images took 0.0330 secs\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/ipykernel/__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09 Feb 2017 14h30m28s][INFO] Fetching 1 images took 0.0231 secs\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda2/envs/harsimrat-code/lib/python2.7/site-packages/ipykernel/__main__.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>images</th>\n",
       "      <th>GnDTruth</th>\n",
       "      <th>0.0_no_resize</th>\n",
       "      <th>0.3_no_resize</th>\n",
       "      <th>3.0_no_resize</th>\n",
       "      <th>20.0_no_resize</th>\n",
       "      <th>299_fullconv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42050402</td>\n",
       "      <td><img src=http://cdn.eyeem.com/thumb/w/200/ceb704440991517303f0ae74a4b58e7bfb383043-1406043086></td>\n",
       "      <td>[wooden, shadow, dark, stairs, iron, building, architecture, close-up, contrasts, romantic, cast iron, trail, no people, detail, sunlight]</td>\n",
       "      <td>[sunlight, no people, high angle view, close-up, outdoors, shadow, day, vertical, color image, photography]</td>\n",
       "      <td>[sunlight, no people, vertical, shadow, high angle view, close-up, outdoors, day, color image, photography]</td>\n",
       "      <td>[vertical, sunlight, shadow, no people, transportation, dark, close-up, bench, high angle view, day]</td>\n",
       "      <td>[sunlight, vertical, shadow, no people, close-up, transportation, dark, high angle view, bench, day]</td>\n",
       "      <td>[no people, pattern, shadow, high angle view, sunlight, close-up, outdoors, art, creativity, day]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a file with following columns: \n",
    "#(png_img,gnd,noresize_beta=0.0,noresize_beta=20.0,noresize_beta=3.0,299)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "size=1899\n",
    "#betas=[0.0,0.01,0.1,0.15,0.16,0.2,0.3,0.4,0.9,1.0,2.0,3.0,20.0]\n",
    "betas=[0.0,0.3,3.0,20.0]\n",
    "topk=10\n",
    "tester.im_h=size\n",
    "tester.im_w=size\n",
    "tester.resize_test=False\n",
    "run_threshold=True\n",
    "concepts=np.array(tester.concepts)\n",
    "\n",
    "\n",
    "\n",
    "inds_topk=dict()\n",
    "\n",
    "#ind_imgs_preds=dict()\n",
    "GnDTruth=[]\n",
    "labs_preds=[]\n",
    "\n",
    "#Initialize the pandas. Rerun previous cell.\n",
    "df['GnDTruth']=np.nan\n",
    "for beta in betas:\n",
    "    df[str(beta)+'_no_resize']=np.nan\n",
    "#------------------\n",
    "\n",
    "for i,name_ in enumerate(subset_filenames):\n",
    "    \n",
    "    pix,basenames=tester.fetch_images([name_])\n",
    "    (predictions, features) = tester.inference(pix)\n",
    "    for beta in betas:\n",
    "        #Aggregate prediction using given beta\n",
    "        preds=preds_Aggr(features,beta)[0]\n",
    "        preds=preds[0,:]\n",
    "        preds=sigmoid(preds)\n",
    "        #Apply Threshold.\n",
    "        if run_threshold==True:\n",
    "            thresholded_preds=tester.run_thresholds(zip(concepts,preds))\n",
    "            preds = [p[1] for p in thresholded_preds]\n",
    "            thresholded_concepts_list=np.array([p[0] for p in thresholded_preds])\n",
    "            #display topk predictions only.\n",
    "            if len(preds)>10:\n",
    "                inds_preds=np.argsort(preds)[::-1]\n",
    "                _topk=inds_preds[0:topk]\n",
    "                df[str(beta)+'_no_resize'][i] = thresholded_concepts_list[_topk]\n",
    "            else:\n",
    "                inds_preds=np.argsort(preds)[::-1]\n",
    "                df[str(beta)+'_no_resize'][i] = thresholded_concepts_list[inds_preds]\n",
    "            \n",
    "        #---------------\n",
    "        else:\n",
    "            #Original- (without threshold)\n",
    "            inds_preds=np.argsort(preds)[::-1]\n",
    "            inds_topk[beta]=inds_preds[0:topk]\n",
    "            df[str(beta)+'_no_resize'][i] = concepts[inds_topk[beta]]\n",
    "        \n",
    "\n",
    "    df['GnDTruth'][i] = gnd[basenames[0]]\n",
    "\n",
    "\n",
    "#This block is seperate because we have to resize image.\n",
    "size=299\n",
    "topk=10\n",
    "tester.im_h=size\n",
    "tester.im_w=size\n",
    "tester.resize_test=True\n",
    "\n",
    "df['299_fullconv']=np.nan\n",
    "\n",
    "for i,name_ in enumerate(subset_filenames):\n",
    "    # Fetch images and apply model\n",
    "    pix,basenames=tester.fetch_images([name_])\n",
    "    (predictions, features) = tester.inference(pix)\n",
    "    #Aggregate using beta\n",
    "    preds=preds_Aggr(predictions,beta)[0]\n",
    "    preds=preds[0,:]\n",
    "    \n",
    "    if run_threshold==True:\n",
    "        thresholded_preds=tester.run_thresholds(zip(concepts,preds))\n",
    "        new_preds = [p[1] for p in thresholded_preds]\n",
    "        thresholded_concepts_list=np.array([p[0] for p in thresholded_preds])\n",
    "        if len(preds)>10:\n",
    "            inds_preds=np.argsort(new_preds)[::-1]\n",
    "            _topk=inds_preds[0:topk]\n",
    "            df['299_fullconv'][i] = thresholded_concepts_list[_topk]\n",
    "        else:\n",
    "            inds_preds=np.argsort(preds)[::-1]\n",
    "            df['299_fullconv'][i] = thresholded_concepts_list[inds_preds]\n",
    "    else:\n",
    "    \n",
    "        inds_preds=np.argsort(preds)[::-1]\n",
    "        _topk=inds_preds[0:topk]\n",
    "        df['299_fullconv'][i] = concepts[_topk]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#HTML(df.to_html(escape=False))   \n",
    "with open('my_file.html', 'w') as fo:\n",
    "    fo.write(df.to_html(escape=False))\n",
    "#HTML(df.to_html(escape=False)) #uncomment to display it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#set the input size of image\n",
    "size=1899\n",
    "beta=0.0\n",
    "tester.im_h=size\n",
    "tester.im_w=size\n",
    "tester.resize_test=False\n",
    "#-----------------------------------------------------------\n",
    "#Fetch the prediction and softpool the output feature map\n",
    "\n",
    "pix,basenames,orig_image=tester.fetch_images([image_filenames[1000]])\n",
    "(predictions, features) = tester.inference(pix)\n",
    "preds=f(predictions,beta)[0]\n",
    "\n",
    "\n",
    "indexes=np.argsort(preds[0,:])[-20:]\n",
    "print \"Predictions by the model:%s\"%np.array(tester.concepts)[indexes]\n",
    "#print \"Ground truth:\"\n",
    "\n",
    "print gnd[basenames[0]]\n",
    "pl.imshow(orig_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds=f(predictions,beta)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indexes=np.argsort(preds[0,:])[-5:]\n",
    "\n",
    "print indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLen=len(subset_filenames)\n",
    "sLen * ['None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "df = pd.DataFrame(range(5), columns=['a'])\n",
    "df['b'] = df['a'].apply(lambda x:'<img src=http://example.com/{0}.png\"/>'.format(x))\n",
    "#df['b'] = df['a'].apply(lambda x:HTML('<img src=\"image01.png\"/>'.format('79025016')))\n",
    "\n",
    "#df2 = pd.DataFrame({ 'A' : [1.], 'B' : [2]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HTML(df.to_html(escape=False))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tester.tester.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "engine     = sqlalchemy.create_engine('mysql+pymysql://ro:rj5XYM4V9QKwy5XScdG@mysql.ro.eyeem.com')\n",
    "connection = engine.connect()\n",
    "\n",
    "IDs = [89736945, 89875528]\n",
    "\n",
    "query = \"SELECT id, filename, width, height FROM eyeem.eyeem_photo WHERE id IN (%s)\" % str(IDs).strip(\"[]\")\n",
    "\n",
    "query_results = connection.execute(query)\n",
    "\n",
    "IDs, filenames, widths, heights = zip(*query_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "IDs=[]\n",
    "for i in image_filenames:\n",
    "    IDs.append(os.path.splitext(os.path.basename(i))[0])\n",
    "query = \"SELECT id, filename, width, height FROM eyeem.eyeem_photo WHERE id IN (%s)\" % str(IDs).strip(\"[]\")\n",
    "query_results = connection.execute(query)\n",
    "#query_results = connection.execute(query)\n",
    "IDs_existing, filenames, widths, heights = zip(*query_results)\n",
    "ID_=[]\n",
    "for i in IDs_existing:\n",
    "    ID_.append(str(i))\n",
    "IDs_existing=ID_\n",
    "\n",
    "IDs_filenames=dict(zip(IDs_existing,filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "IDs_filenames\n",
    "\n",
    "# IDs=list(IDs)\n",
    "# IDs_existing=list()\n",
    "# from numpy import int64\n",
    "\n",
    "#len(list(set.intersection(set(ID_),set(IDs_existing))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create an HTML file for display of results.\n",
    "\n",
    "from IPython.display import HTML,Image\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "df = pd.DataFrame(list([IDs[3]]), columns=['a'])\n",
    "df['b'] = df['a'].apply(lambda x:\"<img src=http://cdn.eyeem.com/thumb/w/100/{0}>\".format(IDs_filenames[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.to_html(escape=False))\n",
    "\n",
    "with open('my_file.html', 'w') as fo:\n",
    "    fo.write(df.to_html(escape=False))\n",
    "HTML(df.to_html(escape=False))\n",
    "#df['b'][0]\n",
    "#HTML(\"<img src='http://cdn.eyeem.com/thumb/w/420/ff2acdc6006dc744f5bfb3650364a6de23096850-1468589859534'>\")\n",
    "#print pd.get_option('display.max_colwidth')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_html(escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"beta\"][0]=['ab','xy']\n",
    "\n",
    "HTML(df.to_html(escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.permutation(range(len(IDs_existing)))[0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:harsimrat-code]",
   "language": "python",
   "name": "conda-env-harsimrat-code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
